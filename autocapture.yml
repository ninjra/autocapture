mode:
  mode: "local"
  # Remote mode: set this to your overlay adapter (e.g. tailscale0, wg0). When
  # remote mode is enabled, api.bind_host is derived from this interface.
  overlay_interface: null
  https_enabled: false
  tls_cert_path: null
  tls_key_path: null
  google_oauth_client_id: null
  google_oauth_client_secret: null
  google_allowed_emails: []
api:
  # Remote mode: bind_host is derived from mode.overlay_interface unless you
  # override it.
  bind_host: "127.0.0.1"
  port: 8008
  require_api_key: false
  api_key: null
  rate_limit_rps: 2.0
  rate_limit_burst: 5
  max_page_size: 200
  default_page_size: 50
  max_query_chars: 2000
  max_context_k: 50
security:
  local_unlock_enabled: true
  session_ttl_seconds: 300
  provider: "windows_hello"
templates:
  enabled: true
  log_provenance: true
ui:
  overlay_citations_enabled: false
overlay_tracker:
  enabled: false
  platforms: ["windows"]
  stale_after_hours: 48
  hotness_half_life_minutes: 30
  collectors:
    foreground_enabled: true
    input_enabled: true
    fallback_foreground_poll_ms: 1000
    input_poll_ms: 250
    input_debounce_ms: 500
  ui:
    enabled: true
    dock: "right"
    width_px: 320
    click_through_default: true
    interactive_timeout_seconds: 10
    refresh_ms: 1000
    auto_hide_fullscreen: true
  hotkeys:
    toggle_overlay:
      modifiers: ["ctrl", "shift"]
      key: "O"
    interactive_mode:
      modifiers: ["ctrl", "shift"]
      key: "I"
    project_cycle:
      modifiers: ["ctrl", "shift"]
      key: "P"
    toggle_running:
      modifiers: ["ctrl", "shift"]
      key: "R"
    rename:
      modifiers: ["ctrl", "shift"]
      key: "N"
    snooze:
      modifiers: ["ctrl", "shift"]
      key: "S"
    snooze_minutes: [15, 60, 240]
  policy:
    deny_processes: []
    max_window_title_length: 512
  retention:
    event_days: 14
    event_cap: 200000
  url_plugin:
    enabled: false
    allow_browsers: ["chrome.exe", "msedge.exe"]
    allow_domains: []
    token_rules: []
offline: true
privacy:
  cloud_enabled: false
  sanitize_default: true
  extractive_only_default: true
  paused: false
  snooze_until_utc: null
  exclude_monitors: []
  exclude_processes:
    - "1password.exe"
    - "bitwarden.exe"
    - "keepass.exe"
    - "keepassxc.exe"
    - "lastpass.exe"
    - "dashlane.exe"
    - "nordpass.exe"
    - "keeper.exe"
    - "roboform.exe"
    - "authy.exe"
  exclude_window_title_regex:
    - "(?i)\\b(inprivate|incognito)\\b"
    - "(?i)windows security"
    - "(?i)user account control"
    - "(?i)credential(s)?"
  exclude_regions: []
output:
  format: "text"
  context_pack_format: "json"
  allow_tron_compression: false
presets:
  active_preset: "privacy_first"
routing:
  capture: "local"
  ocr: "local"
  embedding: "local"
  retrieval: "local"
  reranker: "enabled"
  compressor: "extractive"
  verifier: "rules"
  llm: "ollama"
llm:
  provider: "ollama"
  ollama_url: "http://127.0.0.1:11434"
  ollama_model: "llama3"
  openai_api_key: null
  openai_model: "gpt-4.1-mini"
  timeout_s: 60.0
  retries: 3
  # Repeat the user prompt once (higher input tokens; may improve non-reasoning tasks).
  prompt_repetition: false
llm_governor:
  enabled: true
  min_in_flight: 1
  max_in_flight: 4
  low_pressure_threshold: 0.45
  high_pressure_threshold: 0.85
  adjust_interval_s: 5.0
promptops:
  enabled: false
  schedule_cron: "0 6 * * 1"
  sources: []
  github_token: null
  github_repo: "https://github.com/ninjra/promptops"
  # Phase 1 settings (PromptOps)
  max_iterations: 3
  max_llm_attempts_per_prompt: 3
  eval_repeats: 3
  eval_aggregation: "worst_case"
  require_improvement: true
  min_delta_verifier_pass_rate: 0.02
  min_delta_citation_coverage: 0.02
  min_delta_refusal_rate: 0.02
  min_delta_latency_ms: 200.0
  acceptance_tolerance: 0.02
  tolerance_citation_coverage: 0.02
  tolerance_refusal_rate: 0.02
  tolerance_latency_ms: 250.0
  min_verifier_pass_rate: 0.60
  min_citation_coverage: 0.60
  max_refusal_rate: 0.30
  max_mean_latency_ms: 15000.0
  max_source_bytes: 1048576
  max_source_excerpt_chars: 2000
  max_sources: 32
agents:
  enabled: true
  max_pending_jobs: 5000
  nightly_cron: "0 3 * * *"
  answer_agent:
    enabled: true
  vision:
    provider: "ollama"
    model: "llava"
    base_url: null
    api_key: null
    max_jobs_per_hour: 20
    run_only_when_idle: true
    idle_hours_start: 22
    idle_hours_end: 6
enrichment:
  enabled: true
  scan_interval_s: 900.0
  max_events_per_scan: 2000
  window_days: null
  at_risk_hours: 24
threads:
  enabled: true
  max_gap_minutes: 15.0
  app_similarity_threshold: 0.5
  title_similarity_threshold: 0.3
  max_events_per_thread: 100
capture:
  hid:
    min_interval_ms: 500
    idle_grace_ms: 1500
    duplicate_threshold: 0.02
    duplicate_window_s: 10.0
    duplicate_max_items: 16
    duplicate_pixel_threshold: 2.5
    fps_soft_cap: 0.5
    block_fullscreen: true
  fps_min: 0.5
  fps_max: 2.0
  tile_size: 512
  fullscreen_primary: true
  fullscreen_width: 3840
  focus_crop_enabled: true
  focus_crop_size: 512
  focus_crop_reference: "event"
  diff_epsilon: 0.04
  downscale_width: 256
  always_store_fullres: false
  thumbnail_width: 640
  # staging_dir: "%LOCALAPPDATA%/Autocapture/staging"  # optional override
  # data_dir: "%LOCALAPPDATA%/Autocapture/data"       # optional override
  encoder: "nvenc_webp"
  record_video: false
  multi_monitor_enabled: true
  hdr_enabled: false
  layout_mode: "virtual_desktop"
  video_bitrate: "8M"
  video_preset: "p4"
  max_pending: 8000
tracking:
  enabled: true
  db_path: "db/host_events.sqlite"
  queue_maxsize: 20000
  flush_interval_ms: 1000
  foreground_poll_ms: 250
  clipboard_poll_ms: 250
  track_mouse_movement: true
  mouse_move_sample_ms: 50
  enable_clipboard: false
  retention_days: null
ocr:
  queue_maxsize: 4000
  batch_size: 32
  max_latency_s: 900
  engine: "rapidocr-onnxruntime"
  device: "cuda"
  languages: ["en"]
  output_format: "json"
  layout_enabled: true
  paddle_ppstructure_enabled: false
  paddle_ppstructure_model_dir: null
  paddle_ppstructure_use_gpu: false
embed:
  text_model: "BAAI/bge-base-en-v1.5"
  image_model: "google/siglip2-so400m-patch14-384"
  text_batch_size: 256
  image_batch_size: 32
  schedule_cron: "0 */6 * * *"
  use_half_precision: true
reranker:
  enabled: true
  model: "BAAI/bge-reranker-v2-m3"
  top_k: 100
worker:
  # data_dir: "%LOCALAPPDATA%/Autocapture/data"       # optional override
  lease_ms: 60000
  ocr_lease_ms: 60000
  embedding_lease_ms: 60000
  poll_interval_s: 1.0
  ocr_backlog_soft_limit: 5000
  ocr_max_attempts: 5
  ocr_workers: 4
  embed_workers: 1
  embedding_max_attempts: 5
retention:
  video_days: 3
  roi_days: 7
  max_media_gb: 200
  screenshot_ttl_days: 30
storage:
  image_quota_gb: 250
  prune_grace_days: 90
  prune_batch: 3000
database:
  # url: "sqlite:///C:/Path/To/Autocapture/data/autocapture.db"  # optional override
  echo: false
  pool_size: 10
  max_overflow: 10
qdrant:
  enabled: true
  url: "http://127.0.0.1:6333"
  # binary_path: "C:/Path/To/qdrant.exe"  # optional override
  text_collection: "text_spans"
  image_collection: "image_tiles"
  text_vector_size: 768
  image_vector_size: 768
  distance: "Cosine"
  hnsw_ef_construct: 128
  hnsw_m: 16
  search_ef: 64
ffmpeg:
  enabled: true
  require_bundled: true
  relative_path_candidates:
    - "ffmpeg/bin/ffmpeg.exe"
    - "ffmpeg/ffmpeg.exe"
encryption:
  enabled: true
  key_provider: "windows-credential-manager"
  key_name: "autocapture/nas-aes-key"
  chunk_size: 4194304
observability:
  prometheus_bind_host: "127.0.0.1"
  prometheus_port: 9005
  prometheus_port_fallbacks: 10
  prometheus_fail_fast: false
  grafana_url: "http://localhost:3000"
  enable_gpu_stats: true
