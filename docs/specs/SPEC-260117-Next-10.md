# SPEC-260117: Next-10 Improvements (contracts + pillars + retrieval tiers + CI gates)

Source: User prompt in this chat; frozen verbatim into repo docs for traceability.
Frozen at: 2026-01-19
Input hash (sha256): b1ca374809d8a8ae5c4bd96423a38376d871d97faf4f3a7c28b24195f4d3cab3

```text
Context:
  environment_summary:
    host_os: "Windows 11 (dev via WSL2); runtime target is Windows-only"
    runtime_target: "Windows-only local agent (service + UI) with permissioned capture"
    gpu: "Optional; no hard GPU dependency for MVP"
    repo_state: "Unknown. Assume an existing prototype repo with capture/extract/index/retrieve/answer components, but missing formal contracts + Next-10 trust guarantees."
    configuration_assumptions:
      - "SQLite is the system-of-record (or can be introduced with minimal disruption)."
      - "CI is GitHub Actions (or similar) and can run on windows-latest."
      - "Local-first posture: no required network services for core pipeline."
  provided_input_references:
    - id: "SPEC-260117"
      title: "Next-10 Improvements (contracts + pillars + retrieval tiers + CI gates)"
      source: "User prompt in this chat; freeze verbatim into repo docs for traceability."
  execution_constraints:
    performance:
      - "Implement deterministic stage budgets + timeouts; record degrade markers; never block indefinitely."
      - "Tier skipping must be explainable and recorded (tier_plan_decision)."
    security:
      - "Hard invariant: excluded frames must never be persisted as pixels and must never create artifacts/spans/index entries."
      - "Masked frames: irreversibly obscure sensitive regions BEFORE persistence; never store unmasked pixels."
      - "Protect local data at rest: prefer SQLCipher + DPAPI; if not feasible, add an explicit secure-mode gate so the app cannot silently run without at-rest protection."
      - "No background upload; no cloud-default indexing; offline-first."
    reproducibility:
      - "Canonical JSON for hashing; stable ID generation for idempotent writes; pin index/engine versions in config and record them in DB."
      - "Deterministic retrieval scoring and sentence splitting for coverage calculations."
    minimal_diffs:
      - "Additive-only schema changes with migrations; never delete or repurpose columns."
      - "Feature-flag optional tiers (SPARSE/LATE) and optional engines (sqlite-vec/Qdrant/ONNX reranker)."
      - "Keep existing user-visible behavior unless explicitly superseded by pillar enforcement and ‘No Evidence’ rules."
  diagnostic_metadata:
    timestamp_utc: "2026-01-18T00:00:00Z"
    input_hash_sha256: "b1ca374809d8a8ae5c4bd96423a38376d871d97faf4f3a7c28b24195f4d3cab3"
  assumed_tools:
    - git
    - gh                # optional, for PR creation
    - dotnet            # if repo is .NET (likely for Windows.Graphics.Capture)
    - powershell        # CI scripts on Windows
    - python3           # report generation + CI gate scripts (portable)
    - sqlite3
    - (optional) sqlcipher
    - (optional) onnxruntime
    - (optional) qdrant
    - (optional) ruff/pytest/mypy  # only if repo is Python

---
analysis
  - Repo inventory (no design-by-assumption):
    - Detect language/runtime: enumerate solutions/projects (e.g., *.sln / csproj) OR python packages OR mixed.
    - Locate current capture path: confirm whether Windows.Graphics.Capture is already used; identify fallback (Desktop Duplication) and permission flow.
    - Locate persistence: find any existing DB/schema; identify whether SQLite is already in use; check for encryption at rest today.
    - Locate extraction pipeline: OCR/VLM/table/entity modules; identify where “artifacts” and “spans” are produced (or missing).
    - Locate retrieval: identify existing lexical/vector indexes; confirm whether multi-tier orchestration exists.
    - Locate answer composition: identify how citations are represented today (if at all) and what UI payloads exist.
    - Locate CI workflows; list current gates; identify where to plug new gates.
  - Gap mapping against SPEC-260117:
    - Confirm presence/absence of each Must (M1–M5), especially:
      - M1: versioned additive contracts + system-of-record with referential integrity + ledger append-only + idempotent writes
      - M2: retrieval tiers FAST/RERANK/FUSION with fused ranking and per-tier scores persisted
      - M3: deterministic pillar enforcement rules (budgets, sensitivity CI, privacy scanner, coverage/provenance/integrity + No Evidence)
      - M4: implement all 10 improvements end-to-end
      - M5: exclusion/masking invariants + at-rest protection
  - Choose implementation defaults that minimize risk:
    - DB encryption default: prefer SQLCipher + DPAPI key wrapping if feasible in the repo’s licensing/dependencies; otherwise implement a strict “secure_mode_required=true” startup guard that refuses to run without at-rest protection (no silent downgrade).
    - Vector search: if repo already has one, integrate; otherwise add a minimal, pinned sqlite-vec integration behind a feature flag with lexical-only fallback (still supporting FAST/FUSION semantics).
    - Rerank: implement an interface + deterministic baseline reranker; add ONNX local model support behind a feature flag (no network downloads in CI).
    - Benchmarks: create a small, synthetic-but-realistic offline benchmark corpus committed to repo or generated deterministically at test time.

plan
  - Branching:
    - Create a feature branch: "spec-260117-next-10" from main.
  - Freeze requirements in-repo:
    - Add docs/specs/SPEC-260117-Next-10.md containing the user-provided spec verbatim (or as close as possible), plus a short “Implementation Notes” appendix mapping repo modules to the spec.
  - Deliverables (must all land in this single PR):
    1) Contracts + DB + migrations implementing FrameRecord, ArtifactRecord, CitableSpan, RetrievalHit, AnswerRecord, ProvenanceLedgerEntry (versioned/additive)
    2) Retrieval Orchestrator with tier plan + persisted hits + fused ranking (FAST/RERANK/FUSION)
    3) Deterministic pillar enforcement implementation:
       - Performant: stage budgets + degrade markers + cancellable stages
       - Accurate: conflict detection + retrieval sensitivity CI gate
       - Secure: privacy gate + privacy regression scanner CI gate + at-rest protection gate
       - Citable: coverage scoring + provenance ledger + integrity checks + No Evidence mode
    4) Implement the 10 “Next-10” improvements with tests and CI gates:
       - coverage scoring, sensitivity ±1 CI, provenance ledger, latency contracts, privacy scanner,
         conflict detection, adaptive tier skipping, citation integrity detection,
         pillar-aware PR enforcement, No Evidence mode
    5) Observability: stage timings + coverage/mode metrics + privacy counters sufficient to make gates actionable.
  - Success criteria:
    - All new CI gates pass on windows-latest.
    - Privacy invariants verified (excluded leakage count = 0).
    - Provenance chain verification succeeds for integration answers.
    - Coverage scoring works and is stored in AnswerRecord.
    - Citation integrity failures are detected and mark answers stale deterministically.
    - Tier skipping decisions are recorded and never skip FAST lexical.
    - “No Evidence” mode is reachable only via deterministic triggers and is user-visible.

implement
  - 0) Repo scaffolding + spec freeze
    - Add docs/specs/SPEC-260117-Next-10.md (verbatim spec) and docs/architecture/next-10-overview.md (repo-specific mapping).
    - Add config defaults under version control (e.g., config/defaults/):
      - policy.json (exclusion/masking rules; at minimum include per-app and window_title regex support)
      - budgets.json (stage contracts + degrade rules)
      - tiers.json (tier knobs: k_lex, k_vec, rerank_N, thresholds, fusion_k, etc.)
  - 1) Core contracts (versioned, additive)
    - Create a Contracts module/package with:
      - FrameRecord (schema_version, privacy_flags, frame_hash, media_path nullable when excluded)
      - ArtifactRecord (schema_version, engine metadata, derived_from)
      - CitableSpan (schema_version, span_hash, bbox, offsets, expires_at_utc NULL, tombstoned)
      - RetrievalHit (schema_version, per-tier scores, tier, citable boolean)
      - AnswerRecord (schema_version, answer_format_version, mode, coverage, confidence, budgets, stale)
      - ProvenanceLedgerEntry (schema_version, entry_type, chain_json, prev_hash, entry_hash)
    - Enforce “additive and versioned”:
      - Add schema_version fields to each contract; default=1.
      - Serialization must be forward-compatible: unknown fields ignored; new fields optional with defaults.
      - Implement canonical JSON serialization for hashing (sorted keys, stable numeric formatting).
  - 2) System-of-record SQLite with referential integrity + idempotent writes
    - Add/extend a DB migration system:
      - schema_migrations table with monotonic version numbers; migrations are additive only.
      - Ensure PRAGMA foreign_keys=ON for every connection.
      - Make migrations idempotent and safe to retry.
    - Apply the provided DDL, with necessary additive tweaks to satisfy M1 (versioning + ledger append-only):
      - Add schema_version columns to frame_record, citable_span, retrieval_hit, answer_record, provenance_ledger_entry (default 1, not null).
      - Add triggers to enforce append-only provenance_ledger_entry:
        - BEFORE UPDATE/DELETE ON provenance_ledger_entry => RAISE(ABORT, 'append-only')
      - Consider (optional but recommended) triggers to prevent UPDATE/DELETE on answer_record if “append-only answers” is desired; otherwise document that deleting answers is a destructive admin operation requiring explicit tooling.
    - Implement idempotent write patterns:
      - Prefer content-derived IDs for artifacts/spans (hash-based) to avoid duplicates on retries.
      - Use INSERT ... ON CONFLICT DO NOTHING for first-write-wins tables.
      - For cases where retries might attempt different payload under same ID, detect mismatch and fail loudly (Secure + Accurate).
  - 3) At-rest protection (M5)
    - Implement a StorageSecurity module:
      - Key management via Windows DPAPI:
        - On first run: generate random master key; protect with DPAPI; store protected blob locally.
        - On subsequent runs: unprotect master key via DPAPI.
      - SQLCipher path (preferred):
        - If SQLCipher is available in repo/tooling: initialize encrypted SQLite using DPAPI-protected key.
      - If SQLCipher is not feasible:
        - Implement a strict “secure_mode_required” gate:
          - Default secure_mode_required=true in production config.
          - If DB is not encrypted and secure_mode_required=true => refuse to start with explicit error explaining how to enable SQLCipher (or allow insecure dev mode).
        - Still encrypt media at rest (AES-GCM) using the DPAPI-protected master key.
    - MediaStore:
      - Write media files encrypted (AES-GCM) with per-file nonce; store metadata (nonce, tag) alongside file or in DB.
      - Ensure frame_hash is computed from post-mask pixels before encryption (so integrity checks can re-validate deterministically if needed).
  - 4) Capture boundary privacy gate (M5 hard invariants)
    - Implement/extend Policy Gate with deterministic rules:
      - Inputs: app_name, window_title, process metadata, optional URL/domain (if available), user pause state.
      - Outputs: privacy_flags = {excluded, masked, capture_paused} and optional mask regions.
      - MUST enforce: excluded => do not persist pixels; do not enqueue extraction; do not create artifacts/spans/index entries.
      - masked => apply irreversible mask to pixels BEFORE hashing/encryption/persistence.
    - Capture implementation:
      - Primary: Windows.Graphics.Capture with permissioned capture flow.
      - Fallback: Desktop Duplication (only if needed and policy allows).
      - For CI and tests: implement a FakeCaptureSource producing deterministic frames + metadata without needing real OS capture.
    - Persist FrameRecord even for excluded frames (allowed by spec) with media_path NULL and excluded=true, but nothing downstream.
  - 5) Extraction + Span Normalization (“evidence atoms”)
    - Ensure extraction workers never run on excluded frames:
      - Guard at queue enqueue (preferred) AND guard at worker start (defense-in-depth).
    - ArtifactRecord:
      - Populate derived_from.frame_hash and upstream_artifact_ids[].
      - Record source_engine + engine_version.
    - CitableSpan:
      - Build stable offsets using a per-frame concatenation record (frame_concat):
        - concat_text is deterministic ordering of extracted text sources.
        - start/end offsets refer to concat_text.
      - span_hash must be deterministic (text + offsets + bbox + frame_hash, canonicalized).
      - expires_at_utc always NULL (indefinite retention); use tombstoned for integrity handling.
  - 6) Index writers (FAST tier support + invariants)
    - Lexical:
      - Create span_fts (FTS5) over CitableSpan.text with unindexed span_id/event_id/frame_id columns.
      - Ensure updates/inserts are idempotent; prefer explicit writer that upserts corresponding FTS rows when new spans arrive.
      - Guarantee excluded frames never appear (should be impossible by upstream invariants; still add an indexer-level guard that refuses spans whose frame is excluded).
    - Dense (optional but recommended):
      - If vector index exists, integrate it using span_id as key and store metadata for filtering.
      - If none exists, add sqlite-vec behind feature flag:
        - Pin extension version; add a compatibility test that loads the extension and runs a trivial query.
        - Provide a deterministic “hash embedder” for CI to avoid large model downloads.
    - Record index operations in provenance ledger (entry_type=index) with index_version, doc_id/span_id.
  - 7) Retrieval Orchestrator with tier plan (M2) + persisted RetrievalHit[]
    - Implement a tier planner:
      - Inputs: query_text, filters, budgets, query_class, tier_stats.
      - Outputs: ordered tiers to run (must include FAST lexical; may include dense; optional rerank).
      - Record plan + skipped_tiers + reasons in tier_plan_decision (always).
    - FAST tier:
      - Run lexical search (FTS) with k_lex.
      - Run dense search (if enabled) with k_vec.
      - Persist RetrievalHit rows (tier=FAST) with scores_json containing per-signal scores.
    - FUSION tier:
      - Fuse candidate lists using RRF (k=60 default) or configured method.
      - Persist RetrievalHit rows (tier=FUSION) with fused score.
    - RERANK tier:
      - If budget allows and policy says, rerank top-N fused candidates.
      - Implement a reranker interface:
        - Default deterministic baseline reranker (e.g., normalized lexical + dense similarity).
        - Optional ONNX cross-encoder behind feature flag (model file must be vendored or explicitly user-provided; no CI downloads).
      - Persist RetrievalHit rows (tier=RERANK) with rerank score and updated fused score.
    - Citable flag computation (contract rule):
      - For each hit with span_id: citable=true only if span exists, tombstoned=0, bbox present, and media exists/readable.
      - Store citable in retrieval_hit.citable; store reasons for noncitable in scores_json or a parallel diagnostics channel.
    - Provenance ledger:
      - Append retrieve:start and retrieve:done entries including tier plan, tiers executed, and hit_ids produced.
  - 8) Improvement (1): Evidence-coverage scoring (sentence coverage MVP)
    - In Answer Orchestrator:
      - Implement deterministic sentence splitting:
        - Regex-based splitter with a curated abbreviation list and tests.
        - Assign stable sentence_id (e.g., incremental + hash of sentence text).
      - For each sentence:
        - Determine if it has ≥1 valid citation (span_id) in answer_citation.
        - In NO_EVIDENCE mode: exclude “meta” sentences from denominator.
      - Compute coverage JSON:
        - sentence_coverage, evidence_count (distinct valid span_id), noncitable_used, uncited_sentences[] (optional diagnostics)
      - Enforce:
        - If NORMAL mode and sentence_coverage < MIN_COVERAGE_NORMAL => downgrade confidence.coverage and/or force NO_EVIDENCE if retrieval_strength low.
      - Persist:
        - answer_record.coverage_json and answer_citation rows.
      - Add regression tracking hooks for CI (coverage_report.json).
  - 9) Improvement (10): User-visible “No Evidence” mode
    - Implement deterministic triggers:
      - No citable hits above threshold after allowed tiers
      - sentence_coverage < MIN_COVERAGE_NOEVIDENCE for factual answers
      - Citation integrity invalidates too many citations
      - Conflicts unresolved and cannot be resolved within budgets
    - Implement NO_EVIDENCE response payload:
      - answer_text explicitly says “No evidence found in your captured data for …”
      - hints[] are nearest matches (clearly labeled uncited; citable=false)
      - actions[] are deterministic query refinements (time/app/keyword) derived from query and available metadata
    - UI wiring:
      - Ensure UI renders mode badge and separates cited evidence from uncited hints.
  - 10) Improvement (6): Evidence conflict detection + CONFLICT mode
    - Implement ConflictDetector module:
      - Inputs: top-N fused CitableSpan + timestamps + optional entity outputs.
      - Extract candidate (entity, field)->values groups using deterministic patterns:
        - numbers/currency/status/date patterns + entity extraction if present
      - Normalize values (currency parsing, date canonicalization, case folding).
      - Decide conflict:
        - If ≥2 distinct values above MIN_VALUE_CONF:
          - If timestamps show explainable change-over-time => annotate as “changed over time”
          - Else => conflict=true
      - Output conflict_summary containing conflicting values + citations + timestamps and recommended mode.
    - Answer Orchestrator enforcement:
      - In CONFLICT mode: must not output one definitive value without disclosure; present a conflict panel with cited alternatives.
  - 11) Improvement (8): Citation integrity detection (no expiry; broken references)
    - Implement IntegrityChecker used on:
      - Answer render, citation click, and a background sampling job
    - Checks per cited span_id:
      - span exists and tombstoned=0
      - frame_record exists
      - media_path exists and file is readable/decryptable
      - (optional sampled) recompute frame_hash and compare to stored frame_hash
    - On failure:
      - Mark citation invalid in UI response
      - Set answer_record.stale=1
      - Recompute coverage/confidence with invalid citations removed
      - Optional repair path (fast):
        - Re-run retrieval excluding invalid spans; if still insufficient => flip to NO_EVIDENCE deterministically
    - Background job:
      - Low-priority validator sampling recent answers; emits stale-answer metrics.
  - 12) Improvement (3): Capture-to-answer provenance ledger (append-only + hash-chained)
    - Implement LedgerWriter API:
      - Append-only insert; idempotent by ledger_id.
      - entry_hash = SHA-256(canonical_json(entry) + prev_hash)
      - prev_hash is previous entry_hash in the answer’s chain (or a global stream if you choose; document which).
    - Ensure chain resolution supports:
      - capture(frame_id, frame_hash) → extract(artifact_id, span_id, engine_version) → index(index_name, doc_id, index_version)
        → retrieve(query_id, hit_id, tier) → answer(sentence_id, claim_id, span_id)
    - Enforce citation emission:
      - Answer Orchestrator may not emit a citation unless the provenance chain for that span is present for this answer_id.
      - If chain missing => treat as noncitable and re-plan answer (or go NO_EVIDENCE).
  - 13) Improvement (4): Latency budget contracts per stage (Performant)
    - Add BudgetManager:
      - Loads budgets.json; produces per-stage budgets and a request deadline.
      - Exposes remaining time and allowed degrade actions.
      - Provides cancellable timeouts for each stage.
    - Integrate with Retrieval Orchestrator + Answer Orchestrator:
      - Enforce stage timeouts; no unbounded retries.
      - Apply deterministic degrade rules:
        - reduce_k, skip_rerank, disable_dense_if_slow, return_fast_only, force_no_evidence_mode_if_low_strength
      - Persist budgets_json with stage_ms_used and degraded_stages[] in AnswerRecord.
  - 14) Improvement (7): Adaptive retrieval tier skipping
    - Implement deterministic query classification:
      - length buckets, numeric/time words, filters presence, request type signals
      - output query_class stored in query_record
    - Track tier usefulness:
      - A tier “helped” if it introduced ≥1 final cited span_id not present before it ran.
      - Update tier_stats with window_n, help_rate, p50_ms, p95_ms (rolling window).
    - Skip policy:
      - Never skip FAST lexical.
      - Skip tier t if help_rate(qc,t) < 0.05 over window_n≥200 AND p95_ms high relative to remaining budget AND retrieval_strength already strong.
      - Guardrails:
        - If FAST yields no citable hits, do not skip escalation unless budget exhausted.
        - For FACT_NUMERIC_TIMEBOUND, do not skip rerank if any numeric candidate exists.
    - Record every decision in tier_plan_decision with reasons + budgets snapshot.
  - 15) Improvement (2): Retrieval sensitivity analysis (±1 stress) as CI gate
    - Add a benchmark harness:
      - Uses a deterministic local dataset (committed fixtures or generated deterministically).
      - Runs baseline C0 and perturbations C± (k_lex ±Δ, k_vec ±Δ, rerank_N ±Δ, threshold ±ε, fusion variant ±1).
      - Computes:
        - Jaccard overlap of top-K span_id
        - mode flip rate (NORMAL/NO_EVIDENCE/CONFLICT)
        - coverage delta
      - Aggregates instability score; writes instability_report.json.
    - CI enforcement:
      - Fail if mean instability > T_mean OR mode flip rate > T_flip; keep thresholds modest initially and ratchet later.
  - 16) Improvement (5): Privacy regression scanner (CI + local)
    - Add a synthetic privacy corpus + pipeline runner:
      - Generates frames with window_title containing EXCLUDE_MARKER_123 and/or image/text markers.
      - Runs through capture→policy→persistence→(attempted) extraction→indexing.
    - Scanner assertions (must be hard gates):
      - Excluded frames: media_path is NULL; no media file exists; no artifacts; no spans; no index entries; searches for marker return empty.
      - Masked frames: media exists and differs from original in masked region; ensure no unmasked pixels persisted.
    - Output privacy_report.json; fail CI on any leakage.
  - 17) Improvement (9): Pillar-aware PR enforcement (CI)
    - Add a required pillars declaration mechanism:
      - Accept either:
        - docs/pillars/*.md added/modified in the PR, OR
        - PILLARS.md updated
      - Provide a template in repo (docs/pillars/TEMPLATE.md).
    - Add CI script that:
      - Verifies pillars declaration exists.
      - Verifies at least one enforcement artifact is present in diff:
        - tests added/modified OR metrics/report thresholds updated OR budgets/policy gating updated.
      - Fails CI if missing.
  - 18) Pillar enforcement wiring (runtime)
    - Centralize deterministic enforcement rules:
      - Performant: budgets + degrade markers always recorded; stages must be cancellable.
      - Accurate: conflict detection + sensitivity CI gate; no silent resolution of conflicts.
      - Secure: privacy gate + regression scanner; excluded never stored; at-rest protection gate.
      - Citable: coverage scoring thresholds; provenance chain required; integrity checks; explicit NO_EVIDENCE behavior.
    - Ensure Answer Orchestrator output always includes:
      - mode (NORMAL/NO_EVIDENCE/CONFLICT)
      - citations (if any) + coverage + confidence + budgets + degraded stages
  - 19) Observability (minimum viable)
    - Add structured logs + metrics counters:
      - capture: excluded_rate, masked_rate
      - extraction: queue depth, span count/frame
      - retrieval: tier latency p50/p95, skip rate, degraded stages
      - answer: sentence_coverage distribution, NO_EVIDENCE rate, CONFLICT rate, stale rate
      - privacy scanner results
    - Include a trace_id per query/answer and propagate through ledger entries for debugging.

test
  - Add/extend unit tests:
    - Deterministic sentence splitter test suite (abbreviations, decimals, punctuation edge cases).
    - Coverage scoring tests:
      - NORMAL mode enforces MIN_COVERAGE_NORMAL behavior
      - NO_EVIDENCE meta-sentence denominator rules
    - Ledger hashing tests:
      - canonical JSON hashing stable
      - hash-chain validation passes
      - append-only triggers prevent update/delete
    - Integrity checker tests:
      - simulate missing media file => citation invalid + answer stale + recomputed coverage
    - Conflict detector tests:
      - conflicting numeric values => CONFLICT mode suggested
      - monotonic timestamp change => “changed over time” not a conflict
    - Tier planner tests:
      - never skip FAST lexical
      - guardrails for FACT_NUMERIC_TIMEBOUND
  - Add integration tests (end-to-end on synthetic corpus):
    - Pipeline run that produces spans, indexes them, answers a query with citations, and verifies:
      - citations resolve end-to-end
      - provenance chain exists and validates
      - coverage >= threshold for NORMAL answers
    - No Evidence determinism scenarios:
      - query with no matching spans reliably yields NO_EVIDENCE and includes deterministic actions/hints.
    - Privacy regression harness:
      - excluded markers produce 0 artifacts/spans/index hits; media_path null.
  - Add CI jobs (windows-latest) to run gates listed in spec:
    - pillar gate (PR declaration + enforcement artifact)
    - privacy regression scanner
    - provenance chain verifier
    - coverage regression benchmark (coverage_report.json)
    - latency budget regression (latency_report.json) on synthetic workload
    - retrieval sensitivity ±1 (instability_report.json)
    - no evidence determinism suite
    - conflict scenario suite
    - citation integrity simulation (delete media; expect stale + invalid citations)
  - Make tests deterministic:
    - Fix random seeds; avoid time-based flakiness; use synthetic monotonic timestamps.
    - Avoid large model downloads; use deterministic embedder for tests if needed.

document
  - Update docs to make the system auditable:
    - docs/specs/SPEC-260117-Next-10.md (frozen requirements)
    - docs/architecture/next-10-overview.md (repo mapping)
    - docs/security/privacy-invariants.md:
      - exclusion/masking invariants
      - at-rest encryption choices + secure_mode_required behavior
      - how to run privacy scanner locally
    - docs/ops/ci-gates.md:
      - describes each gate, inputs, outputs (coverage_report.json, instability_report.json, latency_report.json, privacy_report.json)
    - docs/retrieval/tiering.md:
      - tier planner, RRF fusion, tier stats, skip policy
    - docs/citations/provenance.md:
      - how citations are validated, how ledger chain resolves capture→answer
  - Add docs/pillars/SPEC-260117.md containing:
    - Pillars Declaration (improves/risks/enforcement points/regression tests)

commit
  - Commit strategy (multiple commits, single PR):
    1) "docs(spec-260117): freeze spec + add config defaults"
    2) "db(contracts): add versioned contracts + migrations + ledger append-only"
    3) "privacy: policy gate + encrypted media store + regression scanner"
    4) "retrieval: tier orchestrator + budgets + tier skipping + stats"
    5) "answer: coverage scoring + no-evidence + conflict mode + citation integrity"
    6) "ci: pillar gate + sensitivity ±1 + coverage/latency/provenance gates"
  - Ensure each commit keeps build green where feasible; if unavoidable, keep breakage localized and immediately fixed in next commit.
  - Include rollback guidance in commit messages / docs:
    - DB migrations are additive; rollback by restoring previous DB snapshot for local dev.
    - Feature flags allow disabling new optional tiers/engines if needed.

PR
  - Create exactly ONE GitHub pull request from branch "spec-260117-next-10" to main:
    - Title: "SPEC-260117: Next-10 trust + stability improvements (pillars enforced)"
    - Description must include:
      - Summary mapping to M1–M5 and the 10 improvements
      - Pillars Declaration (and link to docs/pillars/SPEC-260117.md)
      - CI artifacts produced + how to interpret them
      - Security notes: exclusion/masking invariants and at-rest encryption posture
      - Known limitations / follow-ups (optional tiers, model-based reranker, etc.)
    - Attach/quote key report excerpts (coverage, latency, instability, privacy) as PR artifacts or logs.
  - Before opening PR:
    - Run full test suite + all gate scripts locally (or on a Windows runner if required).
    - Ensure no network calls are introduced in core pipeline or CI.
  - After PR creation:
    - Confirm all required checks are green.
    - Do not merge until the pillar gate, privacy scanner, provenance verifier, and sensitivity gate all pass.
```
